name: spark-jupyterlab

services:
  spark-master:
      container_name: da-spark-master
      build: .
      image: da-spark-image
      entrypoint: ['./entrypoint.sh', 'master']
      healthcheck:
        test: [ "CMD", "curl", "-f", "http://localhost:8080" ]
        interval: 5s
        timeout: 3s
        retries: 3
      env_file:
        - scripts/.env.spark
      ports:
        - '8080:8080'
        - '7077:7077'
        - '8888:8888'
        - '4040:4040'

  spark-history-server:
    container_name: da-spark-history
    image: da-spark-image
    entrypoint: ['./entrypoint.sh', 'history']
    depends_on:
      spark-master:
        condition: service_healthy
    env_file:
      - scripts/.env.spark
    ports:
      - '18080:18080'

  spark-worker:
    # container_name: da-spark-worker # This is not required for workers as for scaling up/down dynamic names will be allocated by the docker.
    image: da-spark-image
    entrypoint: ['./entrypoint.sh', 'worker']
    depends_on:
      spark-master:
        condition: service_healthy
    env_file:
      - scripts/.env.spark